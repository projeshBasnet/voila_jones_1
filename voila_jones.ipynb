{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# VOILA JONES ALGORITHM "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Introduction"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Voila Jones  algorithm is used for object detection  without using deep learning technique. It was formulated by Paul Viola and Michael Jones. It is still a popular algorithm used till now especially for face detection.**\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Working Principle"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "There are mainly four steps in object detection using voila jones\n",
    "* Haar features\n",
    "* Integral image\n",
    "* Adaboost\n",
    "* Cascading"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Haar Features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Various Haar features are used as shown in image below and they are used identify various facial features like eyes, nose, eyebrows etc.\n",
    "\n",
    "These Haar features are like a kernel and a single value is obtained by subtracting sum of pixel under white rectangle from sum of pixel under black region.\n",
    "Voila Jones used 24*24 sub-window for calcuating Haar features that resembles some characteristics of facial component."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img scr=\"https://upload.wikimedia.org/wikipedia/commons/thumb/2/2f/Prm_VJ_fig1_featureTypesWithAlpha.png/330px-Prm_VJ_fig1_featureTypesWithAlpha.png\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/2/2f/Prm_VJ_fig1_featureTypesWithAlpha.png/330px-Prm_VJ_fig1_featureTypesWithAlpha.png\" alt=\"image\"/>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here, if we consider all possible Haar features in a single window than we end up with more than 160,000 features considering various position,scale of Haar features which is huge for computation. So, we exclude the features which are not useful.For this purpose we use adaboost techinique to remove the unwanted features."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Integral Image"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As we know, we have to find the difference of sum of white pixel and sum of black pixel, here to acquire computational efficenecy, we use techinique called integral image where we can calcuate sum of a specific region using less computational power. The figure showing transformation of normal image array to integral image is given below "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"https://www.researchgate.net/profile/Zuzana-Kepesiova/publication/324554906/figure/fig1/AS:724520499425280@1549750556472/mage-conversion-to-summed-area-table-also-known-as-Integral-image.ppm\" />"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Integral Image is calcuated by adding all the elements to its top and left. Here if we wish to find the middle element of original input element than we add right adjecent element which is '6' with diagonal element of '6' which is '1' and subtract it with sum of left adjecent element which is '2' and its dioganal element'3'.Thus result is 1."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Adaboost"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Any irrelevant features which are not important to be considered among 160,000 + features in 24*24 subwindow are filtered using adaboost algorithm. For example ,any feature which donot contains components of faces in it can be excluded. A strong classifier is created by adaboost by linear combination of weak classifier. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Cascading"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In cascasding , number of features are stagged in a herichacial order by creating a cascade like structure. Each 24*24 subwindow features are fed through this cascade and if it passes certain thersehold value in overall window than only it is passed to next stage of cascade. This helps to filter the block of images which donot contains facial patterns and these blocks are ignored. This helps us to save compuational power on unnecessary blocks of images."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Example of Haar cascade in python"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import cv2 as cv\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# xml file used here is present locally\r\n",
    "face_cascade = cv.CascadeClassifier('front_face.xml')\r\n",
    "eye_cascade = cv.CascadeClassifier('harcascade_eye.xml')\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "cap = cv.VideoCapture(0)\r\n",
    "while True:\r\n",
    "    ret,img = cap.read()\r\n",
    "    gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\r\n",
    "    face = face_cascade.detectMultiScale(gray,scaleFactor=1.5,minNeighbors=5)\r\n",
    "    for (x,y,w,h) in face:\r\n",
    "        cv.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)\r\n",
    "        roi_color = img[y:y+h,x:x+w]\r\n",
    "        roi_gray = gray[y:y+h,x:x+w]\r\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray,scaleFactor=1.5,minNeighbors=5)\r\n",
    "        for (ex,ey,ew,eh) in eyes:\r\n",
    "            cv.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,0,255),2)\r\n",
    "        \r\n",
    "    cv.imshow(\"Image\",img)\r\n",
    "    \r\n",
    "    if cv.waitKey(1) & 0xff == ord('q'):\r\n",
    "        break\r\n",
    "\r\n",
    "cap.release()\r\n",
    "cv.destroyAllWindows()\r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}